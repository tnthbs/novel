import requests,bs4,re
#import time

def getContent(url,head):
    req = requests.get(url,headers = head)
    req.encoding = 'GBK'
    bs = bs4.BeautifulSoup(req.text,'lxml')
    #nameText = bs.find('h1').string #获取章节名称
    nameText = bs.find('h1').get_text()
    contentText = bs.find('div',attrs = {'id':'content'}).get_text()  #get content,换行符丢失
    contentText = contentText.replace('\xa0\xa0\xa0\xa0','\n\n   ') #0xa0无法被utf-8识别，补上换行符及替换成空格
    return nameText,contentText

def saveFile(bookName,nameText,contentText):    #writing chapter and content
#    with open(bookName + '.txt', "a",) as f:
    f.write('\n\n')                                        #每章前增加换行，排版美观
    f.write(nameText)
    f.write(contentText)
    print(nameText + ' 下载完成')        

def getBookname(url,head):
    bookUrl = url.split('/')
    bookUrl = bookUrl[:-1]
    bookUrl = '/'.join(bookUrl)  #getbbok name url
    req = requests.get(bookUrl,headers = head)
    req.encoding = 'GBK'
    bs = bs4.BeautifulSoup(req.text,'lxml')
    bookname = bs.find('h1').get_text()
    return bookUrl,bookname


def getUrl(url,head):
    req = requests.get(url,headers = head)
    req.encoding = 'GBK'
    bs = bs4.BeautifulSoup(req.text,'lxml')
    for a in bs.find_all('a'):  #get all a value
        if '下一章' in a:   #there is 下一章option
            if a['href'] != 'index.html': #下一章不是回到首页时，为真正的下一章
                return a['href']
            else:
                print('next is index')
                return False      
       

#starttime = time.time()
url = 'https://www.booktxt.net/5_5170/2372499.html'  #first chapter
head = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'}
nameText,contentText = getContent(url,head)  #save the firstpage
bookUrl,bookName = getBookname(url,head)
with open(bookName + '.txt', "a",) as f:
    saveFile(bookName,nameText,contentText)    #保存第一章
    #for i in range(10):  #test
    while getUrl(url,head):
        url = bookUrl + '/'+ getUrl(url,head)  #get next page url
        nameText,contentText = getContent(url,head)
        saveFile(bookName,nameText,contentText)
    
#endtime = time.time()
#endtime - starttime
